{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinal Disease Detection and Classification\n",
    "\n",
    "## By: Jalen Wu, Yechan Na, Jonathan Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Project Description:__\n",
    "\n",
    "The goal of this project is to develop a machine learning model capable of detecting retinal diseases by analyzing fundus images of the eye. Using computer vision and deep learning techniques, the model assists in early detection and diagnosis of retinal disease(s).\n",
    "\n",
    "__Applications and Impact:__\n",
    "\n",
    "This project could be used for clinical screening to help ophthalmologists identify diseases and improve efficiency on identifying these diseases. This automated detection system has the potential to make medical imaging diagnostics more accessible.\n",
    "\n",
    "__What we hope to achieve:__\n",
    "\n",
    "We hope to build a model that takes in images of the eye and accurately predicts whether an individualâ€™s eyes are healthy or showing signs of disease. To quantify the effectiveness of our model, we will be measuring metrics such as F1 score, precision, recall, loss, and accuracy of our models and graphing them as a function of how many epochs we run on our training data (all of these scores should increase in subsequent epochs).\n",
    "\n",
    "- __Dataset__: https://www.kaggle.com/datasets/andrewmvd/retinal-disease-classification/data\n",
    "- __References__: \n",
    "    - https://www.mdpi.com/2306-5729/6/2/14\n",
    "    - https://jamanetwork.com/journals/jama/fullarticle/2588763\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from torch import tensor\n",
    "from PIL import Image\n",
    "from torch import flatten\n",
    "from nltk.metrics.scores import (precision, recall, f_measure, accuracy)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\wendy\\.cache\\kagglehub\\datasets\\andrewmvd\\retinal-disease-classification\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrewmvd/retinal-disease-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wendy\\.cache\\kagglehub\\datasets\\andrewmvd\\retinal-disease-classification\\versions\\1\n",
      "Directory exists and its contents are:\n",
      "['Evaluation_Set', 'Test_Set', 'Training_Set']\n"
     ]
    }
   ],
   "source": [
    "# X = 1424 x 2144 x 3 : h x w x colors\n",
    "# y = label\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((int(1424 / 8), int(2144 / 8))), # Standardize image dimensions to 1444 x 2144\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "base_directory = path  \n",
    "print(base_directory)\n",
    "\n",
    "if os.path.exists(base_directory):\n",
    "    print(\"Directory exists and its contents are:\")\n",
    "    print(os.listdir(base_directory))\n",
    "else:\n",
    "    print(\"Directory does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (paths that will be accessed later in the project)\n",
    "BASE_DIRECTORY = path\n",
    "TRAINING_DIRECTORY = os.path.join(BASE_DIRECTORY, 'Training_Set', 'Training_Set', 'Training')\n",
    "TRAINING_LABELS = os.path.join(BASE_DIRECTORY, 'Training_Set', 'Training_Set', 'RFMiD_Training_Labels.csv')\n",
    "TESTING_DIRECTORY = os.path.join(BASE_DIRECTORY, 'Test_Set', 'Test_Set', 'Test')\n",
    "TESTING_LABELS = os.path.join(BASE_DIRECTORY, 'Test_Set', 'Test_Set', 'RFMiD_Testing_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Supports structure of given dataset (images in child folder and labels in csv format).\n",
    "    \"\"\"\n",
    "    def __init__(self, label_csv_file, image_directory, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_csv_file (str): Path to the CSV label file.\n",
    "            image_directory (str): Directory with eye images.\n",
    "            transform (callable, optional): transform function to be applied to each image.\n",
    "        \"\"\"\n",
    "        self.label_csv_file = pd.read_csv(label_csv_file)\n",
    "        self.image_directory = image_directory\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_csv_file)    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of the image/label pair we want to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            image_and_label (dict): A dictionary containing the image and its corresponding label at the requested index.\n",
    "        \"\"\"\n",
    "\n",
    "        # The images are PNG and one-indexed (1.png, 2.png, 3.png, ...)\n",
    "        image_path = os.path.join(self.image_directory, str(index + 1) +'.png')\n",
    "        \n",
    "        image_label = self.label_csv_file.loc[index]\n",
    "        image_label = image_label.to_numpy()\n",
    "        image_label = image_label[1:]\n",
    "        image_label = tensor(image_label)\n",
    "        \n",
    "        # Loads image at the given path.\n",
    "        current_image = io.imread(image_path)\n",
    "        \n",
    "        if current_image is None or current_image.size == 0:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "       \n",
    "        # Convert to PIL Image\n",
    "        current_image = Image.fromarray(current_image)\n",
    "        \n",
    "        # If transform function passed in, apply transform to image\n",
    "        if self.transform:\n",
    "            transformed_image = self.transform(current_image)\n",
    "            return {'image': transformed_image, 'label': image_label}\n",
    "        \n",
    "        return {'image': current_image,'label': image_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 178, 268])\n",
      "torch.Size([64, 46])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Initializing dataset and loader.\n",
    "train_dataset = MultiClassDataset(label_csv_file=TRAINING_LABELS, image_directory=TRAINING_DIRECTORY, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "# Visualize loader\n",
    "res = next(iter(train_loader))\n",
    "print(res['image'].shape)\n",
    "print(res['label'].shape)\n",
    "\n",
    "print(res['label'][0])\n",
    "print(res['image'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 178, 268])\n"
     ]
    }
   ],
   "source": [
    "# image tensor format: [batch_size, channels, height, width]\n",
    "print(res['image'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Conv_NN_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(8640, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 840)\n",
    "        self.fc3 = nn.Linear(840, 230)\n",
    "        self.fc4 = nn.Linear(230, 46)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "conv_model_v2 = Conv_NN_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(1456, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 840)\n",
    "        self.fc3 = nn.Linear(840, 230)\n",
    "        self.fc4 = nn.Linear(230, 46)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "conv_model = Conv_NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    total_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        # get the inputs; data is a dict of [inputs, labels]\n",
    "        inputs = data['image']\n",
    "        labels = data['label']\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MultiClassDataset(label_csv_file=TESTING_LABELS, image_directory=TESTING_DIRECTORY, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRFA(predictions, answers):\n",
    "    pred_indices = [x for x in range(len(predictions)) if predictions[x] == 1]\n",
    "    label_indices = [y for y in range(len(answers)) if answers[y] == 1]\n",
    "\n",
    "    temp_precision = precision(set(pred_indices), set(label_indices)) # actual labels vs. predicted labels\n",
    "    temp_recall = recall(set(pred_indices), set(label_indices))\n",
    "    temp_f1 = f_measure(set(pred_indices), set(label_indices))\n",
    "    temp_accuracy = accuracy(answers, predictions)\n",
    "    return (temp_precision, temp_recall, temp_f1, temp_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    \"\"\"\n",
    "    Takes a dataloader for the test data and model\n",
    "    Returns the Precision, Recall, F1 Score, and Accuracy of the model as a tuple\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    correct_each = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['image']\n",
    "            labels = data['label']\n",
    "            \n",
    "            preds = model(inputs)\n",
    "            \n",
    "            for p_i in range(len(preds)):\n",
    "                for l_i in range(len(preds[p_i])):\n",
    "                    if preds[p_i][l_i] > 0.9:\n",
    "                        preds[p_i][l_i] = 1.0\n",
    "                    else:\n",
    "                        preds[p_i][l_i] = 0.0\n",
    "            \n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    return PRFA(torch.flatten(torch.cat(all_preds)), torch.flatten(torch.cat(all_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [14:28, 28.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.014911880282064279\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cat(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m conv_loss \u001b[38;5;241m>\u001b[39m conv_model_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m p, r, f, a \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m p_scores\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[0;32m     17\u001b[0m r_scores\u001b[38;5;241m.\u001b[39mappend(r)\n",
      "Cell \u001b[1;32mIn[18], line 32\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(dataloader, model)\u001b[0m\n\u001b[0;32m     29\u001b[0m         all_preds\u001b[38;5;241m.\u001b[39mappend(preds)\n\u001b[0;32m     30\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PRFA(torch\u001b[38;5;241m.\u001b[39mflatten(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m), torch\u001b[38;5;241m.\u001b[39mflatten(torch\u001b[38;5;241m.\u001b[39mcat(actual)))\n",
      "\u001b[1;31mTypeError\u001b[0m: cat(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "conv_model_loss = []\n",
    "p_scores = []\n",
    "r_scores = []\n",
    "f_scores = []\n",
    "a_scores = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    conv_loss = train(train_loader, conv_model, loss_fn, optimizer)\n",
    "    print(\"conv_loss: \", conv_loss)\n",
    "    \n",
    "    if t > 3 and conv_loss > conv_model_loss[-1]:\n",
    "        break\n",
    "    \n",
    "    p, r, f, a = test(test_loader, conv_model)\n",
    "    p_scores.append(p)\n",
    "    r_scores.append(r)\n",
    "    f_scores.append(f)\n",
    "    a_scores.append(a)\n",
    "    \n",
    "    conv_model_loss.append(conv_loss)\n",
    "    torch.save(conv_model.state_dict(), \"4th_conv_model.pth\")\n",
    "\n",
    "\n",
    "file = open(\"4th_model_scores.txt\", \"w\", encoding=\"utf8\")\n",
    "file.write(f\"losses: {conv_model_loss} \\n\")\n",
    "file.write(f\"precisions: {p_scores} \\n\")\n",
    "file.write(f\"recalls: {r_scores} \\n\")\n",
    "file.write(f\"f1 scores: {f_scores} \\n\")\n",
    "file.write(f\"accuracies: {a_scores} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "- Plot loss/accuracy (y) with number of epochs ran (x)\n",
    "- Recall/Precision/F1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Conv_NN()\n",
    "conv_model.load_state_dict(torch.load(\"4th_conv_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loss(x, y, graph_name):\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"epoch #\")\n",
    "    plt.ylabel(\"avg loss per epoch\")\n",
    "    plt.title(graph_name)\n",
    "    plt.show()\n",
    "\n",
    "conv_model_loss = [0.11161561645567417, 0.11138974775870641, 0.11114585660398006, 0.11090392681459586, 0.11066602679590384, 0.11043245221177737, 0.11020307466387749, 0.10997721602519353, 0.10975412366290888, 0.10953380366166433, 0.10931579855581125, 0.10909994306663671, 0.10888638297716777, 0.1086751475930214, 0.1084660306572914, 0.1082591944684585, 0.10805465094745159, 0.10785217843949794, 0.10765165475507578, 0.10745289884507656, 0.1072556022554636, 0.10705923375984033, 0.10686317943036557, 0.10666639693081378, 0.10646703901390235, 0.10626155473291873, 0.10604292452335358, 0.10579483682910601, 0.10546997028092543, 0.10488231368362903, 0.10309731836120288, 0.09737458365658919, 0.09468479597320159, 0.09464651898791393, 0.0946396378800273, 0.09463591761887073]\n",
    "\n",
    "graph_loss(range(len(conv_model_loss)), conv_model_loss, \"convolutional model\")\n",
    "print(conv_model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(images[0])\n",
    "# print labels\n",
    "print(classes[labels[0]], images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
