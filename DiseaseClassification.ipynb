{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinal Disease Detection and Classification\n",
    "\n",
    "## By: Jalen Wu, Yechan Na, Jonathan Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Project Description:__\n",
    "\n",
    "The goal of this project is to develop a machine learning model capable of detecting retinal diseases by analyzing fundus images of the eye. Using computer vision and deep learning techniques, the model assists in early detection and diagnosis of retinal disease(s).\n",
    "\n",
    "__Applications and Impact:__\n",
    "\n",
    "This project could be used for clinical screening to help ophthalmologists identify diseases and improve efficiency on identifying these diseases. This automated detection system has the potential to make medical imaging diagnostics more accessible.\n",
    "\n",
    "__What we hope to achieve:__\n",
    "\n",
    "We hope to build a model that takes in images of the eye and accurately predicts whether an individualâ€™s eyes are healthy or showing signs of disease. To quantify the effectiveness of our model, we will be measuring metrics such as F1 score, precision, recall, loss, and accuracy of our models and graphing them as a function of how many epochs we run on our training data (all of these scores should increase in subsequent epochs).\n",
    "\n",
    "- __Dataset__: https://www.kaggle.com/datasets/andrewmvd/retinal-disease-classification/data\n",
    "- __References__: \n",
    "    - https://www.mdpi.com/2306-5729/6/2/14\n",
    "    - https://jamanetwork.com/journals/jama/fullarticle/2588763\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from torch import tensor\n",
    "from PIL import Image\n",
    "from torch import flatten\n",
    "from nltk.metrics.scores import (precision, recall, f_measure, accuracy)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\wendy\\.cache\\kagglehub\\datasets\\andrewmvd\\retinal-disease-classification\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrewmvd/retinal-disease-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wendy\\.cache\\kagglehub\\datasets\\andrewmvd\\retinal-disease-classification\\versions\\1\n",
      "Directory exists and its contents are:\n",
      "['Evaluation_Set', 'Test_Set', 'Training_Set']\n"
     ]
    }
   ],
   "source": [
    "# X = 1424 x 2144 x 3 : h x w x colors\n",
    "# y = label\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((int(1424 / 8), int(2144 / 8))), # Standardize image dimensions to 1444 x 2144\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "base_directory = path  \n",
    "print(base_directory)\n",
    "\n",
    "if os.path.exists(base_directory):\n",
    "    print(\"Directory exists and its contents are:\")\n",
    "    print(os.listdir(base_directory))\n",
    "else:\n",
    "    print(\"Directory does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (paths that will be accessed later in the project)\n",
    "BASE_DIRECTORY = path\n",
    "TRAINING_DIRECTORY = os.path.join(BASE_DIRECTORY, 'Training_Set', 'Training_Set', 'Training')\n",
    "TRAINING_LABELS = os.path.join(BASE_DIRECTORY, 'Training_Set', 'Training_Set', 'RFMiD_Training_Labels.csv')\n",
    "TESTING_DIRECTORY = os.path.join(BASE_DIRECTORY, 'Test_Set', 'Test_Set', 'Test')\n",
    "TESTING_LABELS = os.path.join(BASE_DIRECTORY, 'Test_Set', 'Test_Set', 'RFMiD_Testing_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Supports structure of given dataset (images in child folder and labels in csv format).\n",
    "    \"\"\"\n",
    "    def __init__(self, label_csv_file, image_directory, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_csv_file (str): Path to the CSV label file.\n",
    "            image_directory (str): Directory with eye images.\n",
    "            transform (callable, optional): transform function to be applied to each image.\n",
    "        \"\"\"\n",
    "        self.label_csv_file = pd.read_csv(label_csv_file)\n",
    "        self.image_directory = image_directory\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_csv_file)    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of the image/label pair we want to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            image_and_label (dict): A dictionary containing the image and its corresponding label at the requested index.\n",
    "        \"\"\"\n",
    "\n",
    "        # The images are PNG and one-indexed (1.png, 2.png, 3.png, ...)\n",
    "        image_path = os.path.join(self.image_directory, str(index + 1) +'.png')\n",
    "        \n",
    "        image_label = self.label_csv_file.loc[index]\n",
    "        image_label = image_label.to_numpy()\n",
    "        image_label = image_label[1:]\n",
    "        image_label = tensor(image_label)\n",
    "        \n",
    "        # Loads image at the given path.\n",
    "        current_image = io.imread(image_path)\n",
    "        \n",
    "        if current_image is None or current_image.size == 0:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "       \n",
    "        # Convert to PIL Image\n",
    "        current_image = Image.fromarray(current_image)\n",
    "        \n",
    "        # If transform function passed in, apply transform to image\n",
    "        if self.transform:\n",
    "            transformed_image = self.transform(current_image)\n",
    "            return {'image': transformed_image, 'label': image_label}\n",
    "        \n",
    "        return {'image': current_image,'label': image_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 178, 268])\n",
      "torch.Size([64, 46])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Initializing dataset and loader.\n",
    "train_dataset = MultiClassDataset(label_csv_file=TRAINING_LABELS, image_directory=TRAINING_DIRECTORY, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "# Visualize loader\n",
    "res = next(iter(train_loader))\n",
    "print(res['image'].shape)\n",
    "print(res['label'].shape)\n",
    "\n",
    "print(res['label'][0])\n",
    "print(res['image'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 178, 268])\n"
     ]
    }
   ],
   "source": [
    "# image tensor format: [batch_size, channels, height, width]\n",
    "print(res['image'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Conv_NN_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(8640, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 840)\n",
    "        self.fc3 = nn.Linear(840, 230)\n",
    "        self.fc4 = nn.Linear(230, 46)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "conv_model_v2 = Conv_NN_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(1456, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 840)\n",
    "        self.fc3 = nn.Linear(840, 230)\n",
    "        self.fc4 = nn.Linear(230, 46)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "conv_model = Conv_NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    total_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        # get the inputs; data is a dict of [inputs, labels]\n",
    "        inputs = data['image']\n",
    "        labels = data['label']\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MultiClassDataset(label_csv_file=TESTING_LABELS, image_directory=TESTING_DIRECTORY, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRFA(predictions, answers):\n",
    "    pred_indices = [x for x in range(len(predictions)) if predictions[x] == 1]\n",
    "    label_indices = [y for y in range(len(answers)) if answers[y] == 1]\n",
    "\n",
    "    temp_precision = precision(set(pred_indices), set(label_indices)) # actual labels vs. predicted labels\n",
    "    temp_recall = recall(set(pred_indices), set(label_indices))\n",
    "    temp_f1 = f_measure(set(pred_indices), set(label_indices))\n",
    "    temp_accuracy = accuracy(answers, predictions)\n",
    "    return (temp_precision, temp_recall, temp_f1, temp_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    \"\"\"\n",
    "    Takes a dataloader for the test data and model\n",
    "    Returns the Precision, Recall, F1 Score, and Accuracy of the model as a tuple\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    correct_each = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['image']\n",
    "            labels = data['label']\n",
    "            \n",
    "            preds = model(inputs)\n",
    "            \n",
    "            for p_i in range(len(preds)):\n",
    "                for l_i in range(len(preds[p_i])):\n",
    "                    if preds[p_i][l_i] > 0.9:\n",
    "                        preds[p_i][l_i] = 1.0\n",
    "                    else:\n",
    "                        preds[p_i][l_i] = 0.0\n",
    "            \n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    return PRFA(torch.flatten(torch.cat(all_preds)), torch.flatten(torch.cat(all_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [14:19, 28.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09462826177477837\n",
      "prfa: \n",
      "0.7863829787234042 0.24283837056504598 0.3710843373493976 tensor(0.8936)\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [17:50, 35.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.0946250177298983\n",
      "prfa: \n",
      "0.7821276595744681 0.2479093606690046 0.37648504711183944 tensor(0.8966)\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [16:24, 32.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09462742786854506\n",
      "prfa: \n",
      "0.7821276595744681 0.24797625472207233 0.3765621798811719 tensor(0.8966)\n",
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [16:27, 32.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09462281508992115\n",
      "prfa: \n",
      "0.7812765957446809 0.24938875305623473 0.3780889621087315 tensor(0.8974)\n",
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [16:48, 33.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09462200912336509\n",
      "prfa: \n",
      "0.7821276595744681 0.24764214497440043 0.37617683176422434 tensor(0.8965)\n",
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [16:35, 33.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09461806248873472\n",
      "prfa: \n",
      "0.7812765957446809 0.24945652173913044 0.37816683831101955 tensor(0.8975)\n",
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [14:48, 29.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09461749792098999\n",
      "prfa: \n",
      "0.7821276595744681 0.24757543103448276 0.3760998567628402 tensor(0.8964)\n",
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [21:53, 43.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09461309934655825\n",
      "prfa: \n",
      "0.7812765957446809 0.24952432726284315 0.3782447466007416 tensor(0.8975)\n",
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [15:41, 31.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09461275357753038\n",
      "prfa: \n",
      "0.7821276595744681 0.24737550471063258 0.37586912065439676 tensor(0.8963)\n",
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [16:39, 33.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09460789542645216\n",
      "prfa: \n",
      "0.7812765957446809 0.24966004895295077 0.37840065952184665 tensor(0.8976)\n",
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [25:06, 50.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_loss:  0.09460810863723358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "conv_model_loss = []\n",
    "p_scores = []\n",
    "r_scores = []\n",
    "f_scores = []\n",
    "a_scores = []\n",
    "\n",
    "#conv_model = Conv_NN()\n",
    "#conv_model.load_state_dict(torch.load(\"5th_conv_model.pth\", weights_only=True))\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    conv_loss = train(train_loader, conv_model, loss_fn, optimizer)\n",
    "    print(\"conv_loss: \", conv_loss)\n",
    "    \n",
    "    if t > 3 and conv_loss > conv_model_loss[-1]:\n",
    "        break\n",
    "    \n",
    "    p, r, f, a = test(test_loader, conv_model)\n",
    "    print(\"prfa: \")\n",
    "    print(p, r, f, a)\n",
    "    p_scores.append(p)\n",
    "    r_scores.append(r)\n",
    "    f_scores.append(f)\n",
    "    a_scores.append(a)\n",
    "    \n",
    "    conv_model_loss.append(conv_loss)\n",
    "    torch.save(conv_model.state_dict(), \"5th_conv_model.pth\")\n",
    "\n",
    "\n",
    "    file = open(\"5th_model_scores.txt\", \"w\", encoding=\"utf8\")\n",
    "    file.write(f\"losses: {conv_model_loss} \\n\")\n",
    "    file.write(f\"precisions: {p_scores} \\n\")\n",
    "    file.write(f\"recalls: {r_scores} \\n\")\n",
    "    file.write(f\"f1 scores: {f_scores} \\n\")\n",
    "    file.write(f\"accuracies: {a_scores} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "- Plot loss/accuracy (y) with number of epochs ran (x)\n",
    "- Recall/Precision/F1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7804255319148936, 0.24993186154265468, 0.37861271676300584, tensor(0.8978))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = Conv_NN()\n",
    "conv_model.load_state_dict(torch.load(\"5th_conv_model.pth\", weights_only=True))\n",
    "\n",
    "test(test_loader, conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loss(x, y, metric):\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"epoch #\")\n",
    "    plt.ylabel(f\"{metric} score per epoch\")\n",
    "    plt.title(f\"{metric} Scores\")\n",
    "    plt.savefig(f\"{metric}_plot.png\")\n",
    "    plt.clf()\n",
    "\n",
    "graph_loss(range(len(conv_model_loss)), conv_model_loss, \"Cross Entropy Loss\")\n",
    "graph_loss(range(len(p_scores)), p_scores, \"Precision\")\n",
    "graph_loss(range(len(r_scores)), r_scores, \"Recall\")\n",
    "graph_loss(range(len(f_scores)), f_scores, \"F1\")\n",
    "graph_loss(range(len(a_scores)), a_scores, \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First vs Final Scores:\n",
      "Cross Entropy Loss: 0.09462826177477837 0.09460789542645216\n",
      "Precision: 0.7863829787234042 0.7812765957446809\n",
      "Recall: 0.24283837056504598 0.24966004895295077\n",
      "F1: 0.3710843373493976 0.37840065952184665\n",
      "Accuracy: 0.8936141133308411 0.897554337978363\n"
     ]
    }
   ],
   "source": [
    "print(\"First vs Final Scores:\")\n",
    "print(\"Cross Entropy Loss:\", conv_model_loss[0], conv_model_loss[-1])\n",
    "print(\"Precision:\", p_scores[0], p_scores[-1])\n",
    "print(\"Recall:\", r_scores[0], r_scores[-1])\n",
    "print(\"F1:\", f_scores[0], f_scores[-1])\n",
    "print(\"Accuracy:\", float(a_scores[0]), float(a_scores[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(images[0])\n",
    "# print labels\n",
    "print(classes[labels[0]], images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
